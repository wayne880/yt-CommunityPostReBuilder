"""
YouTube Community Post Viewer
Main entry point and CLI interface.
"""

import argparse
import sys
from pathlib import Path
from typing import Optional

from .archiver import PostArchiver
from .channel_fetcher import ChannelFetcher
from .data_processor import DataProcessor
from .html_generator import HTMLGenerator


def main():
    """Main entry point for the CLI."""
    parser = argparse.ArgumentParser(
        description="Archive YouTube community posts and generate a static HTML viewer.",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹ç”¨æ³•:
  # åŸºæœ¬ä½¿ç”¨ - å­˜æª”å…¬é–‹è²¼æ–‡
  yt-community-viewer "https://www.youtube.com/@ChannelName/posts"

  # ä½¿ç”¨ç€è¦½å™¨è¨­å®šæª”ç™»å…¥ä»¥ç²å–æœƒå“¡è²¼æ–‡
  yt-community-viewer "https://www.youtube.com/@ChannelName/posts" -p ~/.config/chromium/

  # ä½¿ç”¨ cookies æª”æ¡ˆ
  yt-community-viewer "https://www.youtube.com/@ChannelName/posts" -c cookies.txt

  # é™åˆ¶æœ€å¤§è²¼æ–‡æ•¸é‡
  yt-community-viewer "https://www.youtube.com/@ChannelName/posts" -m 50

  # åƒ…å¾ç¾æœ‰å­˜æª”ç”¢ç”Ÿæª¢è¦–å™¨ï¼ˆä¸é‡æ–°çˆ¬å–ï¼‰
  yt-community-viewer --generate-only -o my-archive
        """,
    )
    
    parser.add_argument(
        "url",
        nargs="?",
        help="YouTube é »é“ç¤¾ç¾¤è²¼æ–‡ç¶²å€ (ä¾‹å¦‚: https://www.youtube.com/@Channel/posts)",
    )
    
    parser.add_argument(
        "-o", "--output",
        default="archive-output",
        help="è¼¸å‡ºç›®éŒ„ (é è¨­: archive-output)",
    )
    
    parser.add_argument(
        "-m", "--max-posts",
        type=int,
        default=None,
        help="æœ€å¤§è²¼æ–‡æ•¸é‡ (é è¨­: å…¨éƒ¨)",
    )
    
    parser.add_argument(
        "-p", "--browser-profile",
        default=None,
        help="ç€è¦½å™¨è¨­å®šæª”è·¯å¾‘ (ç”¨æ–¼ç™»å…¥æœƒå“¡è²¼æ–‡)",
    )
    
    parser.add_argument(
        "-n", "--profile-name",
        default=None,
        help="ç€è¦½å™¨è¨­å®šæª”åç¨± (é è¨­ä½¿ç”¨ default)",
    )
    
    parser.add_argument(
        "-c", "--cookies",
        default=None,
        help="Netscape æ ¼å¼çš„ cookies æª”æ¡ˆè·¯å¾‘",
    )
    
    parser.add_argument(
        "-d", "--driver",
        choices=["chrome", "firefox"],
        default="chrome",
        help="ä½¿ç”¨çš„ç€è¦½å™¨é©…å‹• (é è¨­: chrome)",
    )
    
    parser.add_argument(
        "--no-headless",
        action="store_true",
        help="é¡¯ç¤ºç€è¦½å™¨è¦–çª— (ç”¨æ–¼é™¤éŒ¯)",
    )
    
    parser.add_argument(
        "--no-members",
        action="store_true",
        help="ä¸ç²å–æœƒå“¡è²¼æ–‡",
    )
    
    parser.add_argument(
        "--skip-channel-info",
        action="store_true",
        help="è·³éç²å–é »é“è³‡è¨Š (é ­åƒ/æ©«å¹…)",
    )
    
    parser.add_argument(
        "--generate-only",
        action="store_true",
        help="åƒ…å¾ç¾æœ‰å­˜æª”ç”¢ç”Ÿ HTML æª¢è¦–å™¨ (ä¸é‡æ–°çˆ¬å–)",
    )
    
    args = parser.parse_args()
    
    # Validate arguments
    if not args.generate_only and not args.url:
        parser.error("è«‹æä¾› YouTube é »é“ç¤¾ç¾¤è²¼æ–‡ç¶²å€ï¼Œæˆ–ä½¿ç”¨ --generate-only å¾ç¾æœ‰å­˜æª”ç”¢ç”Ÿæª¢è¦–å™¨")
    
    try:
        run_archiver(
            url=args.url,
            output_dir=args.output,
            max_posts=args.max_posts,
            browser_profile=args.browser_profile,
            profile_name=args.profile_name,
            cookies_file=args.cookies,
            driver=args.driver,
            headless=not args.no_headless,
            include_members=not args.no_members,
            fetch_channel_info=not args.skip_channel_info,
            generate_only=args.generate_only,
        )
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ä½¿ç”¨è€…ä¸­æ–·æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ç™¼ç”ŸéŒ¯èª¤: {e}")
        sys.exit(1)


def run_archiver(
    url: Optional[str] = None,
    output_dir: str = "archive-output",
    max_posts: Optional[int] = None,
    browser_profile: Optional[str] = None,
    profile_name: Optional[str] = None,
    cookies_file: Optional[str] = None,
    driver: str = "chrome",
    headless: bool = True,
    include_members: bool = True,
    fetch_channel_info: bool = True,
    generate_only: bool = False,
) -> Path:
    """
    Run the complete archiving and HTML generation process.
    
    Args:
        url: YouTube channel community posts URL
        output_dir: Output directory path
        max_posts: Maximum number of posts to archive
        browser_profile: Browser profile path for login
        profile_name: Browser profile name
        cookies_file: Netscape cookies file path
        driver: Browser driver (chrome or firefox)
        headless: Run browser in headless mode
        include_members: Also archive membership posts
        fetch_channel_info: Fetch channel avatar and banner
        generate_only: Only generate HTML from existing archive
        
    Returns:
        Path to the generated index.html
    """
    output_path = Path(output_dir)
    
    print("=" * 60)
    print("ğŸ¬ YouTube ç¤¾ç¾¤è²¼æ–‡å­˜æª”å·¥å…·")
    print("=" * 60)
    
    channel_info = None
    posts = []
    
    if not generate_only:
        # Step 1: Fetch channel info (avatar, banner)
        if fetch_channel_info and url:
            print("\nğŸ“¸ æ­£åœ¨ç²å–é »é“è³‡è¨Š...")
            fetcher = ChannelFetcher(output_dir=output_dir)
            channel_info = fetcher.fetch_channel_info(url)
            
            if channel_info:
                print(f"   é »é“åç¨±: {channel_info.name}")
                print(f"   é »é“ä»£è™Ÿ: {channel_info.handle}")
                if channel_info.local_avatar:
                    print(f"   âœ… å·²ä¸‹è¼‰é ­åƒ")
                if channel_info.local_banner:
                    print(f"   âœ… å·²ä¸‹è¼‰æ©«å¹…")
            else:
                print("   âš ï¸  ç„¡æ³•ç²å–é »é“è³‡è¨Š")
        
        # Step 2: Archive posts
        print("\nğŸ“¥ æ­£åœ¨å­˜æª”ç¤¾ç¾¤è²¼æ–‡...")
        archiver = PostArchiver(
            output_dir=output_dir,
            browser_profile=browser_profile,
            profile_name=profile_name,
            cookies_file=cookies_file,
            driver=driver,
            headless=headless,
        )
        
        # Archive based on authentication availability
        if browser_profile or cookies_file:
            print("   ä½¿ç”¨å·²ç™»å…¥çš„ç€è¦½å™¨è¨­å®šæª”...")
            posts = archiver.archive_channel(
                channel_url=url,
                include_membership=include_members,
                max_posts=max_posts,
            )
        else:
            print("   æœªæä¾›ç™»å…¥è³‡è¨Šï¼Œåƒ…å­˜æª”å…¬é–‹è²¼æ–‡...")
            posts = archiver.archive_channel(
                channel_url=url,
                include_membership=False,
                max_posts=max_posts,
            )
        
        print(f"   å·²å­˜æª” {len(posts)} å‰‡è²¼æ–‡")
    
    else:
        # Load existing archive
        print("\nğŸ“‚ å¾ç¾æœ‰å­˜æª”è¼‰å…¥è³‡æ–™...")
        
        archiver = PostArchiver(output_dir=output_dir)
        posts = archiver.load_archived_posts()
        
        fetcher = ChannelFetcher(output_dir=output_dir)
        channel_info = fetcher.load_channel_info()
        
        print(f"   å·²è¼‰å…¥ {len(posts)} å‰‡è²¼æ–‡")
    
    if not posts:
        print("\nâš ï¸  æ²’æœ‰æ‰¾åˆ°ä»»ä½•è²¼æ–‡è³‡æ–™")
        return output_path / "viewer" / "index.html"
    
    # Step 3: Process data
    print("\nğŸ”„ æ­£åœ¨è™•ç†è³‡æ–™...")
    processor = DataProcessor(output_dir=output_dir)
    processed_data = processor.process_all(posts, channel_info)
    
    # Print statistics
    stats = processor.get_statistics(posts)
    print(f"   å…¬é–‹è²¼æ–‡: {stats['public']}")
    print(f"   æœƒå“¡è²¼æ–‡: {stats['members_only']}")
    print(f"   å«åœ–ç‰‡: {stats['with_images']}")
    print(f"   å«æŠ•ç¥¨: {stats['with_polls']}")
    
    # Step 4: Generate HTML viewer
    print("\nğŸŒ æ­£åœ¨ç”¢ç”Ÿ HTML æª¢è¦–å™¨...")
    generator = HTMLGenerator(output_dir=output_dir)
    index_path = generator.generate(processed_data)
    
    print("\n" + "=" * 60)
    print("âœ¨ å®Œæˆï¼")
    print("=" * 60)
    print(f"\nğŸ“ å­˜æª”ç›®éŒ„: {output_path.absolute()}")
    print(f"ğŸŒ æª¢è¦–å™¨: {index_path.absolute()}")
    print("\nğŸ’¡ åœ¨ç€è¦½å™¨ä¸­é–‹å•Ÿ index.html å³å¯ç€è¦½å­˜æª”å…§å®¹")
    
    return index_path


if __name__ == "__main__":
    main()
